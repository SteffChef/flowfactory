(1) Perceived Benefits 

A use case is considered highly attractive when it generates clear and measurable value for the financial institution. This includes significant cost reductions and efficiency gains resulting from AI-powered automation, particularly in processes such as fraud detection, compliance, and back-office operations (McKinsey, 2023; Alonso-Robisco & Carbó, 2022). Furthermore, AI use cases that drive revenue growth through personalized products, innovative financial services, and enhanced customer targeting offer substantial business potential (Königstorfer & Thalmann, 2020). Improving customer experience through personalization and real-time interactions further strengthens the use case's value proposition, contributing to higher customer retention (Kaur et al., 2020; Maple et al., 2023). Additionally, the ability of AI systems to reduce risks by improving process reliability and minimizing human error is a crucial benefit. Stable, repeatable processes supported by AI can significantly reduce operational and compliance risks (Enholm et al., 2022). 

On the other hand, use cases with low or unclear business value present significant challenges for adoption. If the financial benefits cannot be quantified or the problem addressed is not of strategic importance, the case's attractiveness diminishes (Tehrani et al., 2024). High implementation complexity without a clear return on investment further reduces feasibility and may strain financial and human resources (Prabhu Desai et al., 2025). Additionally, overestimating expected benefits relative to the organization's actual capabilities can lead to unrealistic expectations, failed projects, or resource misallocations (Lakhchini et al., 2022). 

Form 

(2) External Pressure 

In the financial sector, regulatory and compliance requirements play a crucial role in determining the feasibility of AI use cases. A favorable use case fully complies with existing regulations such as the EU AI Act, which governs fairness, transparency, accountability and risk management in AI systems (BIS, 2024). High levels of model explainability, transparency and fairness are essential to ensure that AI systems can be audited and understood by regulators, management and stakeholders (Jöhnk et al., 2021; Maple et al., 2023). Furthermore, competitor adoption of similar AI use cases can validate both relevance and practicality, especially in highly regulated and innovation-driven markets like finance. Observing peer institutions implementing specific use cases provides indirect assurance about regulatory viability and potential business value (Nguyen et al., 2021). 

Conversely, use cases that rely on non-transparent models lacking transparency and explainability face significant regulatory obstacles (Bodendorf, 2025; Cao, 2022). Non-compliance with legal standards can expose the institution to legal sanctions and reputational damage (Reddy et al., 2021). In addition, insufficient attention to data privacy, cybersecurity risks and bias mitigation may result in operational vulnerabilities and undermine trust from customers and regulators alike (Obeng et al., 2024; Hussain & Papastathopoulos, 2022).Form 

(3) Organizational Readiness 

A key factor for the successful adoption of AI use cases is the organization’s internal readiness to implement and operate these solutions. High data quality, comprehensive data availability and mature data pipelines ensure that AI models are trained on reliable and representative data sources (Tehrani et al., 2024; Prabhu Desai et al., 2025). Additionally, the presence of a workforce with dedicated AI expertise - combined with openness toward innovation and clearly defined AI governance structures - plays a critical role. These enable cross-functional collaboration, facilitate compliance with regulatory demands and ensure responsible AI development and deployment (Hussain & Papastathopoulos, 2022). Lastly, the strategic alignment of AI use cases with core business priorities, supported by strong executive sponsorship, ensures the sustainability of AI initiatives. This alignment helps in securing resources and integrating AI into the company’s long-term roadmap (Maple et al., 2023). 

In contrast, limited data availability, fragmented data sources and poor data quality significantly hinder model development and performance (Biallas & O'Neill, 2020; Kaur et al., 2020). Moreover, insufficient AI skills, resistance to organizational change, and a lack of training among staff can delay or prevent successful AI adoption (Jöhnk et al., 2021; Hussain & Papastathopoulos, 2022). Legacy IT systems, fragmented infrastructures, and weak system integration further exacerbate implementation challenges and increase the complexity of operationalizing AI solutions (Cao, 2022; Maple et al., 2023). 